# Wiki_Dictionary
Machine Learning web application to obtain information through Wikipidea. 
Web app is built and deployed using Streamlit and the model is a fine-tuned checkpoint of DistilBERT.
DistilBERT is a small, fast, cheap and light Transformer model trained by distilling BERT base. It has 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERTâ€™s performances as measured on the GLUE language understanding benchmark.
